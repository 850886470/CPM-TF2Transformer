{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colab运行前需要把运行类型修改成GPU类型\n",
    "!pip install transformers jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLNetTokenizer, TFGPT2LMHeadModel\n",
    "\n",
    "tokenizer = XLNetTokenizer.from_pretrained('mymusise/CPM-FP16-Third-Party')\n",
    "model = TFGPT2LMHeadModel.from_pretrained(\"mymusise/CPM-FP16-Third-Party\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextGenerationPipeline\n",
    "import jieba\n",
    "\n",
    "text_generater = TextGenerationPipeline(model, tokenizer)\n",
    "\n",
    "def pre_text(t):\n",
    "    translator = str.maketrans(\" \\n\", \"\\u2582\\u2583\")\n",
    "    seg_list = [x.translate(translator) for x in jieba.cut(t, cut_all=False)]\n",
    "    new_seg = \" \".join(seg_list)\n",
    "    return new_seg\n",
    "\n",
    "texts = [\n",
    "    '今天天气不错',\n",
    "    '天下武功, 唯快不破',\n",
    "]\n",
    "texts = [pre_text(text) for text in texts]\n",
    "\n",
    "def show(result):\n",
    "    display(result[0]['generated_text'].replace('▂', ''))\n",
    "\n",
    "for text in texts:\n",
    "    show(text_generater(text, max_length=20 + len(text)))\n",
    "    show(text_generater(text, max_length=20 + len(text), do_sample=True, top_k=10))\n",
    "    show(text_generater(text, max_length=20 + len(text), do_sample=True, top_k=10, repetition_penalty=2))"
   ]
  }
 ]
}
